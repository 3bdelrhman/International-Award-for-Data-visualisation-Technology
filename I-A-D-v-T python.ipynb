{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"goodgov= pd.read_csv(\"../input/What Makes a Good Government.csv\")\ngoodgov=goodgov.drop(['Unnamed: 10','Unnamed: 22','Unnamed: 4','indicator','ISO Country code'],axis=1).loc[4:198]\ngoodgov.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9dd3440ce7e4e0f3946a498c5717fa33f7eea1b0"},"cell_type":"code","source":"goodgov.columns = goodgov.columns.str.replace(\" \",\"_\").str.replace(\"(\",\"\").str.replace(\")\",\"\").str.replace(\"\\r\\n\",\"\").str.replace(\"%\",\"\")\ngoodgov.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f7d5eff5dcb0cd99f5b69b433809e646d338b03"},"cell_type":"code","source":"cols = goodgov.columns[goodgov.dtypes.eq(object)]\ngoodgov[cols] = goodgov[cols].apply(pd.to_numeric, errors='coerce', axis=0)\nprint(list(cols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17333fbac6a22bb1fcf2c3ed772d6c2c0a912261"},"cell_type":"code","source":"x1 = goodgov.dropna(subset=['happy_planet_index'])\ny1 = x1.happy_planet_index\nx1 = x1.drop(['world_happiness_report_score','human_development_index','happy_planet_index'],axis=1)\nx1 = x1.fillna(x1.mean())\n\n\nx2 = goodgov.dropna(subset=['human_development_index'])\ny2 = x2.human_development_index\nx2 = x2.drop(['world_happiness_report_score','human_development_index','happy_planet_index'],axis=1)\nx2 = x2.fillna(x2.mean())\n\nx3 = goodgov.dropna(subset=['world_happiness_report_score'])\ny3 = x3.world_happiness_report_score\nx3 = x3.drop(['world_happiness_report_score','human_development_index','happy_planet_index'],axis=1)\nx3 = x3.fillna(x3.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f07b811c3c3ef1728fa127a0bd996895862e55d"},"cell_type":"code","source":"import lightgbm as lgbm\nimport xgboost as xgb\n## Import the random forest model.\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\n\nx_train,x_test,y_train,y_test = train_test_split(x1,y1,random_state=123,test_size=0.05)\n\n\n## This line instantiates the model. \nrf = RandomForestRegressor() \n## Fit the model on your training data.\nrf.fit(x_train, y_train) \n\nfeatures = list(x1.columns)\nimportances = rf.feature_importances_\nindices = np.argsort(importances)\n\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.rcParams[\"figure.figsize\"] = [30,25]\nfont = {'family' : 'normal',\n        'weight' : 'bold',\n        'size'   : 25}\n\nplt.rc('font', **font)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cb040bd1ae4cf6a26318bbf8022210e957d58bb"},"cell_type":"code","source":"import lightgbm as lgbm\nimport xgboost as xgb\n## Import the random forest model.\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\n\nx_train,x_test,y_train,y_test = train_test_split(x2,y2,random_state=123,test_size=0.05)\n\n\n## This line instantiates the model. \nrf = RandomForestRegressor() \n## Fit the model on your training data.\nrf.fit(x_train, y_train) \n\nfeatures = list(x1.columns)\nimportances = rf.feature_importances_\nindices = np.argsort(importances)\n\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.rcParams[\"figure.figsize\"] = [30,25]\nfont = {'family' : 'normal',\n        'weight' : 'bold',\n        'size'   : 25}\n\nplt.rc('font', **font)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7127cb8f337fd05fc5818df43ae5e806279aa1f0"},"cell_type":"code","source":"import lightgbm as lgbm\nimport xgboost as xgb\n## Import the random forest model.\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\n\nx_train,x_test,y_train,y_test = train_test_split(x3,y3,random_state=123,test_size=0.05)\n\n\n## This line instantiates the model. \nrf = RandomForestRegressor() \n## Fit the model on your training data.\nrf.fit(x_train, y_train) \n\nfeatures = list(x1.columns)\nimportances = rf.feature_importances_\nindices = np.argsort(importances)\n\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.rcParams[\"figure.figsize\"] = [30,25]\nfont = {'family' : 'normal',\n        'weight' : 'bold',\n        'size'   : 25}\n\nplt.rc('font', **font)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"432aeecbbb9e12fdf51e85212a062b7a33ef26ee"},"cell_type":"code","source":"feature_importances = pd.DataFrame(rf.feature_importances_,\n                                   index = x_train.columns,\n                                    columns=['importance']).sort_values('importance',\n                                                                        ascending=False)\nfeature_importances ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ac73d535e8a80f5de016b8462a533b613bedc3f"},"cell_type":"code","source":"#xgb.plot_importance(model,max_num_features=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca2d4ffc33e2f97fb3ab3a17f29c413114202579"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1adfb50aafaf1dff16305a830ae65b52254da44a"},"cell_type":"code","source":"import xgboost as xgb  \n\nx_train,x_test,y_train,y_test\ndtrain = xgb.DMatrix(x_train, label=y_train,missing=999.0)\ndvalid = xgb.DMatrix(x_test, label=y_test,missing=999.0)\nwatchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n\n# Try different parameters! My favorite is random search :)\nxgb_pars = {'min_child_weight': 10, 'eta': 0.04, 'colsample_bytree': 0.8, 'max_depth': 15,\n            'subsample': 0.75, 'lambda': 2, 'nthread': -1, 'booster' : 'gbtree', 'silent': 1, 'gamma' : 0,\n            'eval_metric': 'rmse', 'objective': 'reg:linear'}  \n\nmodel2 = xgb.train(xgb_pars, dtrain, 500, watchlist, early_stopping_rounds=50,\n                  maximize=False, verbose_eval=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f4c127a4e1481b4c135068c3fb8720d970e0204"},"cell_type":"code","source":"\n\n#feature_names=['population','surface area_Km2','GINI_index']\n\n\ndtrain = xgb.DMatrix(x_train, label=y_train#,missing=-999.0,feature_names=feature_names)\n                    )\ndvalid = xgb.DMatrix(x_test, label=y_test,#missing=-999.0,feature_names=feature_names)\n                    )\nwatchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n\n# Try different parameters! My favorite is random search :)\nxgb_pars = {'min_child_weight': 10, 'eta': 0.04, 'colsample_bytree': 0.8, 'max_depth': 15,\n           'subsample': 0.75, 'lambda': 2, 'nthread': -1, 'booster' : 'gbtree', 'silent': 1, 'gamma' : 0,\n           'eval_metric': 'rmse', 'objective': 'reg:linear'}  \n\nmodel = xgb.train(xgb_pars, dtrain, 500, watchlist, early_stopping_rounds=14,\n                maximize=False, verbose_eval=15)\n#model.save_model('0001.model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75f638c1b69b4cfb748c3171d825c7334a595db9"},"cell_type":"code","source":"\nparams = {\n        'boosting_type':'gbdt',\n        'objective': 'regression',\n        'nthread': 4,\n        'num_leaves': 31,\n        'learning_rate': 0.01,\n        'max_depth': -1,\n        'subsample': 0.8,\n        'bagging_fraction' : 1,\n        'max_bin' : 5000 ,\n        'bagging_freq': 20,\n        'colsample_bytree': 0.6,\n        'metric': 'rmse',\n        'min_split_gain': 0.5,\n        'min_child_weight': 1,\n        'min_child_samples': 10,\n        'scale_pos_weight':1,\n        'zero_as_missing': True,\n        'seed':0,\n        'num_rounds':1000\n    }\n    \ntrain_set = lgbm.Dataset(x_train, y_train#, silent=False,categorical_feature=['year','month','day','weekday'])\n                        )\nvalid_set = lgbm.Dataset(x_test, y_test#, silent=False#,categorical_feature=['year','month','day','weekday'])\n                        )\nmodel = lgbm.train(params, train_set = train_set, num_boost_round=1000,early_stopping_rounds=50,verbose_eval=500, valid_sets=valid_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59ac229669458d4ec1d51087998a2d5b1c1125e5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}